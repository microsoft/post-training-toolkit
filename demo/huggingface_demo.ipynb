{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-Training Toolkit Demo\n",
    "## For the HuggingFace TRL Team\n",
    "\n",
    "**Agenda (10 min)**\n",
    "1. Integration: One line, zero config\n",
    "2. Your GRPO bug: How we'd catch it\n",
    "3. Contributing: YAML heuristics\n",
    "4. Vision: Continuous RL & Agent Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: Integration\n",
    "\n",
    "### The entire integration is ONE line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the ENTIRE integration:\n",
    "\n",
    "from post_training_toolkit import DiagnosticsCallback\n",
    "\n",
    "# trainer = GRPOTrainer(\n",
    "#     model=model,\n",
    "#     callbacks=[DiagnosticsCallback()],  # <-- Just this\n",
    "#     ...\n",
    "# )\n",
    "\n",
    "print(\"That's it. Zero configuration needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto-detects your trainer type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from post_training_toolkit.integrations.trl import TRAINER_CLASS_MAP\n",
    "\n",
    "print(\"Supported trainers (auto-detected):\")\n",
    "for cls, typ in sorted(set((k, v) for k, v in TRAINER_CLASS_MAP.items() if \"Trainer\" in k)):\n",
    "    print(f\"  {cls} ‚Üí {typ}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: The GRPO Bug\n",
    "\n",
    "> \"importance_sampling_ratio wasn't close to 1 (it was mostly ~0)\"\n",
    "\n",
    "Let's simulate this and see how PTT catches it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate: IS ratio starts healthy (~1.0) then collapses (~0.1)\n",
    "is_ratio_good = np.random.normal(1.0, 0.1, 50)  # First 50 steps: healthy\n",
    "is_ratio_bad = np.clip(np.random.normal(0.1, 0.05, 50), 0.01, 0.3)  # Last 50: collapsed\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"step\": list(range(100)),\n",
    "    \"importance_sampling_ratio\": np.concatenate([is_ratio_good, is_ratio_bad]),\n",
    "})\n",
    "\n",
    "print(f\"Steps 0-50:   IS ratio = {df['importance_sampling_ratio'].iloc[:50].mean():.3f} (healthy)\")\n",
    "print(f\"Steps 50-100: IS ratio = {df['importance_sampling_ratio'].iloc[50:].mean():.3f} (PROBLEM!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from post_training_toolkit.models.heuristics import run_heuristics\n",
    "\n",
    "insights = run_heuristics(df, trainer_type=\"grpo\")\n",
    "\n",
    "print(f\"\\nüîç PTT detected {len(insights)} issue(s):\\n\")\n",
    "for insight in insights:\n",
    "    icon = {\"high\": \"üö®\", \"medium\": \"‚ö†Ô∏è\", \"low\": \"‚ÑπÔ∏è\"}.get(insight.severity, \"‚Ä¢\")\n",
    "    print(f\"{icon} [{insight.severity.upper()}] {insight.type}\")\n",
    "    print(f\"   {insight.message}\")\n",
    "    if insight.reference:\n",
    "        print(f\"   Ref: {insight.reference}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Caught during training. Not after."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3: Contributing Heuristics\n",
    "\n",
    "### Adding a heuristic = Writing a YAML file\n",
    "\n",
    "Here's the heuristic that caught the IS ratio bug:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the YAML file:\n",
    "from pathlib import Path\n",
    "\n",
    "yaml_path = Path(\"../post_training_toolkit/heuristics/builtin/grpo/importance_sampling_ratio.yaml\")\n",
    "print(yaml_path.read_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Condition DSL\n",
    "\n",
    "| Syntax | Meaning |\n",
    "|--------|--------|\n",
    "| `< 0.5` | Below threshold |\n",
    "| `> 2.0` | Above threshold |\n",
    "| `range(0.68, 0.71)` | Stuck in range |\n",
    "| `drop(50%)` | Dropped 50% from baseline |\n",
    "| `spike(3x)` | 3x above rolling average |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All conditions parse correctly:\n",
    "from post_training_toolkit.heuristics.parser import parse_condition\n",
    "\n",
    "for cond in [\"< 0.5\", \"> 2.0\", \"range(0.68, 0.71)\", \"drop(50%)\", \"spike(3x)\"]:\n",
    "    result = parse_condition(cond)\n",
    "    print(f\"  '{cond}' ‚Üí {result.type.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Even faster: Inline alerts (no file needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For quick experiments, define alerts inline:\n",
    "\n",
    "cb = DiagnosticsCallback(\n",
    "    custom_alerts=[\n",
    "        \"grpo: importance_sampling_ratio < 0.5 -> high: IS ratio collapsed!\",\n",
    "        \"grpo: entropy drop(50%) for 30 steps -> medium: Entropy dropping\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"Custom alerts registered: {len(cb._custom_alerts)}\")\n",
    "for alert in cb._custom_alerts:\n",
    "    print(f\"  ‚Ä¢ {alert}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 4: Vision - Continuous RL & Agent Training\n",
    "\n",
    "### The Problem with Continuous/Online RL\n",
    "\n",
    "```\n",
    "Offline RLHF:     Train ‚Üí Evaluate ‚Üí Ship ‚Üí Done\n",
    "                         ‚Üë\n",
    "                    Catch problems here\n",
    "\n",
    "Continuous RL:    Train ‚Üí Train ‚Üí Train ‚Üí Train ‚Üí ...\n",
    "                        ‚Üë\n",
    "                  Problems compound silently\n",
    "```\n",
    "\n",
    "**PTT makes continuous RL safe by default.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulating Continuous Training with Live Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def simulate_continuous_training():\n",
    "    \"\"\"Simulate continuous training with live PTT monitoring.\"\"\"\n",
    "    \n",
    "    metrics_history = []\n",
    "    \n",
    "    print(\"üîÑ Simulating continuous GRPO training...\\n\")\n",
    "    \n",
    "    for step in range(100):\n",
    "        # Simulate metrics - IS ratio degrades over time\n",
    "        if step < 40:\n",
    "            is_ratio = np.random.normal(1.0, 0.1)\n",
    "        elif step < 60:\n",
    "            is_ratio = np.random.normal(0.7, 0.1)  # Starting to drift\n",
    "        else:\n",
    "            is_ratio = np.random.normal(0.2, 0.05)  # Collapsed\n",
    "        \n",
    "        metrics_history.append({\n",
    "            \"step\": step,\n",
    "            \"importance_sampling_ratio\": max(0.01, is_ratio),\n",
    "            \"reward_mean\": 0.1 + step * 0.005 + np.random.normal(0, 0.02),\n",
    "        })\n",
    "        \n",
    "        # Run heuristics every 10 steps (like the callback does)\n",
    "        if step > 0 and step % 10 == 0:\n",
    "            df = pd.DataFrame(metrics_history)\n",
    "            insights = run_heuristics(df, \"grpo\")\n",
    "            \n",
    "            high_severity = [i for i in insights if i.severity == \"high\"]\n",
    "            if high_severity:\n",
    "                print(f\"Step {step:3d}: üö® {high_severity[0].message[:60]}...\")\n",
    "            else:\n",
    "                print(f\"Step {step:3d}: ‚úÖ All metrics healthy\")\n",
    "        \n",
    "        time.sleep(0.05)  # Simulate training time\n",
    "    \n",
    "    print(\"\\n‚úã In real training, PTT would have warned you at step 70.\")\n",
    "    print(\"   Without PTT, you might not notice until step 200+.\")\n",
    "\n",
    "simulate_continuous_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Agent Training Angle\n",
    "\n",
    "PTT provides **structured signals** that AI agents can reason over:\n",
    "\n",
    "```python\n",
    "# Instead of parsing 10,000 log lines:\n",
    "[2024-01-21 10:23:45] loss=0.693\n",
    "[2024-01-21 10:23:46] loss=0.694\n",
    "...\n",
    "\n",
    "# AI gets structured insights:\n",
    "Insight(\n",
    "    type=\"dpo_loss_random\",\n",
    "    severity=\"high\",\n",
    "    message=\"Loss stuck at 0.693 (random chance)\",\n",
    "    data={\"expected\": \"< 0.5\", \"actual\": 0.693},\n",
    "    reference=\"Rafailov et al. (2023)\"\n",
    ")\n",
    "```\n",
    "\n",
    "**This is the missing layer for AI-assisted debugging.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary: Why First-Party Integration?\n",
    "\n",
    "| Point | Value |\n",
    "|-------|-------|\n",
    "| **Integration** | One line, zero config |\n",
    "| **Coverage** | All TRL trainers today |\n",
    "| **Contributions** | YAML = no Python required |\n",
    "| **Knowledge** | Encodes tribal knowledge in code |\n",
    "| **Future** | Enables safe continuous RL + agent training |\n",
    "\n",
    "---\n",
    "\n",
    "### One-liners:\n",
    "\n",
    "> \"PTT makes continuous RL safe by default.\"\n",
    "\n",
    "> \"The early-warning system for long-horizon agent training.\"\n",
    "\n",
    "> \"Structured signals for humans AND AI to debug training.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Questions?\n",
    "\n",
    "**Try it yourself:**\n",
    "```bash\n",
    "pip install post-training-toolkit\n",
    "```\n",
    "\n",
    "**Add to any TRL trainer:**\n",
    "```python\n",
    "callbacks=[DiagnosticsCallback()]\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
