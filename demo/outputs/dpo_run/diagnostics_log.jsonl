{"type": "header", "trainer_type": "dpo", "timestamp": "2025-12-10T20:28:12.176867+00:00", "config": {"log_every_n_steps": 1, "include_slices": true}}
{"step": 1, "timestamp": "2025-12-10T20:28:12.336348+00:00", "trainer_type": "dpo", "metrics": {"reward_mean": 0.0, "reward_std": 0.0, "dpo_loss": 0.6931, "win_rate": 0.0, "reward_margin": 0.0, "logps_chosen": -154.274765, "logps_rejected": -64.939636, "logprobs": -154.274765, "rewards_chosen": 0.0, "rewards_rejected": 0.0}}
{"step": 2, "timestamp": "2025-12-10T20:28:12.382475+00:00", "trainer_type": "dpo", "metrics": {"reward_mean": -1e-06, "reward_std": -1e-06, "dpo_loss": 0.6931, "win_rate": 0.75, "reward_margin": -1e-06, "logps_chosen": -102.784546, "logps_rejected": -32.478683, "logprobs": -102.784546, "rewards_chosen": -1e-06, "rewards_rejected": -0.0}}
{"step": 3, "timestamp": "2025-12-10T20:28:12.423562+00:00", "trainer_type": "dpo", "metrics": {"reward_mean": -2e-06, "reward_std": 0.0, "dpo_loss": 0.6931, "win_rate": 0.75, "reward_margin": 0.0, "logps_chosen": -81.237312, "logps_rejected": -51.422501, "logprobs": -81.237312, "rewards_chosen": -2e-06, "rewards_rejected": -2e-06}}
{"step": 4, "timestamp": "2025-12-10T20:28:12.464476+00:00", "trainer_type": "dpo", "metrics": {"reward_mean": -4.9e-05, "reward_std": -5.1e-05, "dpo_loss": 0.6932, "win_rate": 0.0, "reward_margin": -5.1e-05, "logps_chosen": -129.762451, "logps_rejected": -54.125221, "logprobs": -129.762451, "rewards_chosen": -4.9e-05, "rewards_rejected": 2e-06}}
{"step": 5, "timestamp": "2025-12-10T20:28:12.507929+00:00", "trainer_type": "dpo", "metrics": {"reward_mean": 1.6e-05, "reward_std": 2.7e-05, "dpo_loss": 0.6931, "win_rate": 0.75, "reward_margin": 2.7e-05, "logps_chosen": -135.384476, "logps_rejected": -73.086136, "logprobs": -135.384476, "rewards_chosen": 1.6e-05, "rewards_rejected": -1.1e-05}}
{"step": 6, "timestamp": "2025-12-10T20:28:12.602442+00:00", "trainer_type": "dpo", "metrics": {"reward_mean": -4e-06, "reward_std": -2e-06, "dpo_loss": 0.6931, "win_rate": 0.75, "reward_margin": -2e-06, "logps_chosen": -116.399216, "logps_rejected": -51.404171, "logprobs": -116.399216, "rewards_chosen": -4e-06, "rewards_rejected": -2e-06}}
{"step": 7, "timestamp": "2025-12-10T20:28:12.646638+00:00", "trainer_type": "dpo", "metrics": {"reward_mean": -1.5e-05, "reward_std": -1.4e-05, "dpo_loss": 0.6932, "win_rate": 0.5, "reward_margin": -1.4e-05, "logps_chosen": -129.765259, "logps_rejected": -35.183743, "logprobs": -129.765259, "rewards_chosen": -1.5e-05, "rewards_rejected": -1e-06}}
{"step": 8, "timestamp": "2025-12-10T20:28:12.694000+00:00", "trainer_type": "dpo", "metrics": {"reward_mean": 7e-06, "reward_std": 1e-05, "dpo_loss": 0.6931, "win_rate": 1.0, "reward_margin": 1e-05, "logps_chosen": -156.96521, "logps_rejected": -35.182446, "logprobs": -156.96521, "rewards_chosen": 7e-06, "rewards_rejected": -4e-06}}
{"step": 9, "timestamp": "2025-12-10T20:28:12.731830+00:00", "trainer_type": "dpo", "metrics": {"reward_mean": 1e-06, "reward_std": 6e-06, "dpo_loss": 0.6931, "win_rate": 0.5, "reward_margin": 6e-06, "logps_chosen": -89.289452, "logps_rejected": -40.576614, "logprobs": -89.289452, "rewards_chosen": 1e-06, "rewards_rejected": -5e-06}}
{"step": 10, "timestamp": "2025-12-10T20:28:12.762970+00:00", "trainer_type": "dpo", "metrics": {"reward_mean": -2.6e-05, "reward_std": -3.4e-05, "dpo_loss": 0.6932, "win_rate": 0.25, "reward_margin": -3.4e-05, "logps_chosen": -86.654678, "logps_rejected": -73.03933, "logprobs": -86.654678, "rewards_chosen": -2.6e-05, "rewards_rejected": 9e-06}}
{"step": 11, "timestamp": "2025-12-10T20:28:12.852405+00:00", "trainer_type": "dpo", "metrics": {"reward_mean": 1.5e-05, "reward_std": 2.1e-05, "dpo_loss": 0.6931, "win_rate": 1.0, "reward_margin": 2.1e-05, "logps_chosen": -170.4534, "logps_rejected": -48.715385, "logprobs": -170.4534, "rewards_chosen": 1.5e-05, "rewards_rejected": -6e-06}}
{"step": 12, "timestamp": "2025-12-10T20:28:12.893471+00:00", "trainer_type": "dpo", "metrics": {"reward_mean": 1.3e-05, "reward_std": 2e-05, "dpo_loss": 0.6931, "win_rate": 1.0, "reward_margin": 2e-05, "logps_chosen": -148.865387, "logps_rejected": -54.128204, "logprobs": -148.865387, "rewards_chosen": 1.3e-05, "rewards_rejected": -8e-06}}
{"step": 13, "timestamp": "2025-12-10T20:28:13.059241+00:00", "trainer_type": "dpo", "metrics": {"reward_mean": -1.1e-05, "reward_std": -9e-06, "dpo_loss": 0.6932, "win_rate": 0.75, "reward_margin": -9e-06, "logps_chosen": -113.597206, "logps_rejected": -35.213364, "logprobs": -113.597206, "rewards_chosen": -1.1e-05, "rewards_rejected": -2e-06}}
{"step": 14, "timestamp": "2025-12-10T20:28:13.103203+00:00", "trainer_type": "dpo", "metrics": {"reward_mean": -2.8e-05, "reward_std": -2.2e-05, "dpo_loss": 0.6932, "win_rate": 0.5, "reward_margin": -2.2e-05, "logps_chosen": -162.216736, "logps_rejected": -40.607754, "logprobs": -162.216736, "rewards_chosen": -2.8e-05, "rewards_rejected": -6e-06}}
{"step": 15, "timestamp": "2025-12-10T20:28:13.143173+00:00", "trainer_type": "dpo", "metrics": {"reward_mean": 1.1e-05, "reward_std": 1.8e-05, "dpo_loss": 0.6931, "win_rate": 0.75, "reward_margin": 1.8e-05, "logps_chosen": -108.302956, "logps_rejected": -56.844215, "logprobs": -108.302956, "rewards_chosen": 1.1e-05, "rewards_rejected": -7e-06}}
{"step": 16, "timestamp": "2025-12-10T20:28:13.231651+00:00", "trainer_type": "dpo", "metrics": {"reward_mean": -3e-06, "reward_std": -3e-06, "dpo_loss": 0.6931, "win_rate": 0.75, "reward_margin": -3e-06, "logps_chosen": -127.193222, "logps_rejected": -48.697754, "logprobs": -127.193222, "rewards_chosen": -3e-06, "rewards_rejected": -1e-06}}
{"step": 17, "timestamp": "2025-12-10T20:28:13.278904+00:00", "trainer_type": "dpo", "metrics": {"reward_mean": 7e-06, "reward_std": 1.2e-05, "dpo_loss": 0.6931, "win_rate": 1.0, "reward_margin": 1.2e-05, "logps_chosen": -156.965195, "logps_rejected": -35.182453, "logprobs": -156.965195, "rewards_chosen": 7e-06, "rewards_rejected": -4e-06}}
{"step": 18, "timestamp": "2025-12-10T20:28:13.326640+00:00", "trainer_type": "dpo", "metrics": {"reward_mean": -2.2e-05, "reward_std": -2.3e-05, "dpo_loss": 0.6932, "win_rate": 0.25, "reward_margin": -2.3e-05, "logps_chosen": -135.267792, "logps_rejected": -54.109596, "logprobs": -135.267792, "rewards_chosen": -2.2e-05, "rewards_rejected": 0.0}}
{"step": 19, "timestamp": "2025-12-10T20:28:13.395288+00:00", "trainer_type": "dpo", "metrics": {"reward_mean": 2e-05, "reward_std": 3e-05, "dpo_loss": 0.6931, "win_rate": 0.75, "reward_margin": 3e-05, "logps_chosen": -135.38443, "logps_rejected": -73.086128, "logprobs": -135.38443, "rewards_chosen": 2e-05, "rewards_rejected": -1e-05}}
{"step": 20, "timestamp": "2025-12-10T20:28:13.439749+00:00", "trainer_type": "dpo", "metrics": {"reward_mean": -1.2e-05, "reward_std": -3e-06, "dpo_loss": 0.6931, "win_rate": 0.75, "reward_margin": -3e-06, "logps_chosen": -124.34758, "logps_rejected": -35.185524, "logprobs": -124.34758, "rewards_chosen": -1.2e-05, "rewards_rejected": -9e-06}}
{"step": 21, "timestamp": "2025-12-10T20:28:13.524074+00:00", "trainer_type": "dpo", "metrics": {"reward_mean": -4e-06, "reward_std": -4e-06, "dpo_loss": 0.6931, "win_rate": 0.75, "reward_margin": -4e-06, "logps_chosen": -97.41864, "logps_rejected": -48.705624, "logprobs": -97.41864, "rewards_chosen": -4e-06, "rewards_rejected": 0.0}}
{"step": 22, "timestamp": "2025-12-10T20:28:13.566073+00:00", "trainer_type": "dpo", "metrics": {"reward_mean": -1.1e-05, "reward_std": -1e-05, "dpo_loss": 0.6932, "win_rate": 0.75, "reward_margin": -1e-05, "logps_chosen": -124.377937, "logps_rejected": -35.194199, "logprobs": -124.377937, "rewards_chosen": -1.1e-05, "rewards_rejected": -2e-06}}
{"step": 23, "timestamp": "2025-12-10T20:28:13.619108+00:00", "trainer_type": "dpo", "metrics": {"reward_mean": -9e-06, "reward_std": -9e-06, "dpo_loss": 0.6932, "win_rate": 0.5, "reward_margin": -9e-06, "logps_chosen": -138.096054, "logps_rejected": -81.16394, "logprobs": -138.096054, "rewards_chosen": -9e-06, "rewards_rejected": 0.0}}
{"step": 24, "timestamp": "2025-12-10T20:28:13.653927+00:00", "trainer_type": "dpo", "metrics": {"reward_mean": 9e-06, "reward_std": 1.4e-05, "dpo_loss": 0.6931, "win_rate": 1.0, "reward_margin": 1.4e-05, "logps_chosen": -94.715317, "logps_rejected": -35.195183, "logprobs": -94.715317, "rewards_chosen": 9e-06, "rewards_rejected": -5e-06}}
{"step": 24, "timestamp": "2025-12-10T20:28:13.654807+00:00", "trainer_type": "dpo", "metrics": {"dpo_loss": 0.693148}}
{"type": "footer", "trainer_type": "dpo", "total_steps": 24, "timestamp": "2025-12-10T20:28:13.660534+00:00"}
